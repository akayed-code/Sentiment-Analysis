{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf60aaef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Project' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-22168da663ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### Text-classifier-using-concepts-of-NLP-and-DataScience\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m+\u001b[0m \u001b[0mProject\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mEXB\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mAdityaKumar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mAkankshaVerma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mIshikaShrivastav\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Project' is not defined"
     ]
    }
   ],
   "source": [
    "### Text-classifier-using-concepts-of-NLP-and-DataScience\n",
    "''''\n",
    "+ Project-EXB-2\n",
    "+ AdityaKumar\n",
    "+ AkankshaVerma\n",
    "+ IshikaShrivastav\n",
    "+ AnushDubey\n",
    "+ AbhishekKushwaha'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0199d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import req pkgs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import neattext.functions as nfx\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e919322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"emotion_dataset_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd02f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage Act upgrade list tommorow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>eye  true hazel eyeand brilliant  Regular feat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>ugh babe hugggzzz u  babe naamazed nga ako e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Emotion                                               Text  \\\n",
       "0           0  neutral                                             Why ?    \n",
       "1           1      joy    Sage Act upgrade on my to do list for tommorow.   \n",
       "2           2  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3           3      joy   Such an eye ! The true hazel eye-and so brill...   \n",
       "4           4      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "\n",
       "                                          Clean_Text  \n",
       "0                                                NaN  \n",
       "1                     Sage Act upgrade list tommorow  \n",
       "2  WAY HOMEGIRL BABY FUNERAL MAN HATE FUNERALS SH...  \n",
       "3  eye  true hazel eyeand brilliant  Regular feat...  \n",
       "4    ugh babe hugggzzz u  babe naamazed nga ako e...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f94361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "joy         11045\n",
       "sadness      6722\n",
       "fear         5410\n",
       "anger        4297\n",
       "surprise     4062\n",
       "neutral      2254\n",
       "disgust       856\n",
       "shame         146\n",
       "Name: Emotion, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Emotion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb95cf28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Emotion', ylabel='count'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sns.countplot(x='Emotion',data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd959978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BTC_ADDRESS_REGEX',\n",
       " 'CURRENCY_REGEX',\n",
       " 'CURRENCY_SYMB_REGEX',\n",
       " 'Counter',\n",
       " 'DATE_REGEX',\n",
       " 'EMAIL_REGEX',\n",
       " 'EMOJI_REGEX',\n",
       " 'HASTAG_REGEX',\n",
       " 'MASTERCard_REGEX',\n",
       " 'MD5_SHA_REGEX',\n",
       " 'MOST_COMMON_PUNCT_REGEX',\n",
       " 'NUMBERS_REGEX',\n",
       " 'PHONE_REGEX',\n",
       " 'PoBOX_REGEX',\n",
       " 'SPECIAL_CHARACTERS_REGEX',\n",
       " 'STOPWORDS',\n",
       " 'STOPWORDS_de',\n",
       " 'STOPWORDS_en',\n",
       " 'STOPWORDS_es',\n",
       " 'STOPWORDS_fr',\n",
       " 'STOPWORDS_ru',\n",
       " 'STOPWORDS_yo',\n",
       " 'STREET_ADDRESS_REGEX',\n",
       " 'TextFrame',\n",
       " 'URL_PATTERN',\n",
       " 'USER_HANDLES_REGEX',\n",
       " 'VISACard_REGEX',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__generate_text',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__numbers_dict',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " '_lex_richness_herdan',\n",
       " '_lex_richness_maas_ttr',\n",
       " 'clean_text',\n",
       " 'defaultdict',\n",
       " 'digit2words',\n",
       " 'extract_btc_address',\n",
       " 'extract_currencies',\n",
       " 'extract_currency_symbols',\n",
       " 'extract_dates',\n",
       " 'extract_emails',\n",
       " 'extract_emojis',\n",
       " 'extract_hashtags',\n",
       " 'extract_html_tags',\n",
       " 'extract_mastercard_addr',\n",
       " 'extract_md5sha',\n",
       " 'extract_numbers',\n",
       " 'extract_pattern',\n",
       " 'extract_phone_numbers',\n",
       " 'extract_postoffice_box',\n",
       " 'extract_shortwords',\n",
       " 'extract_special_characters',\n",
       " 'extract_stopwords',\n",
       " 'extract_street_address',\n",
       " 'extract_terms_in_bracket',\n",
       " 'extract_urls',\n",
       " 'extract_userhandles',\n",
       " 'extract_visacard_addr',\n",
       " 'fix_contractions',\n",
       " 'generate_sentence',\n",
       " 'hamming_distance',\n",
       " 'inverse_df',\n",
       " 'lexical_richness',\n",
       " 'markov_chain',\n",
       " 'math',\n",
       " 'nlargest',\n",
       " 'normalize',\n",
       " 'num2words',\n",
       " 'random',\n",
       " 're',\n",
       " 'read_txt',\n",
       " 'remove_bad_quotes',\n",
       " 'remove_btc_address',\n",
       " 'remove_currencies',\n",
       " 'remove_currency_symbols',\n",
       " 'remove_custom_pattern',\n",
       " 'remove_custom_words',\n",
       " 'remove_dates',\n",
       " 'remove_emails',\n",
       " 'remove_emojis',\n",
       " 'remove_hashtags',\n",
       " 'remove_html_tags',\n",
       " 'remove_mastercard_addr',\n",
       " 'remove_md5sha',\n",
       " 'remove_multiple_spaces',\n",
       " 'remove_non_ascii',\n",
       " 'remove_numbers',\n",
       " 'remove_phone_numbers',\n",
       " 'remove_postoffice_box',\n",
       " 'remove_puncts',\n",
       " 'remove_punctuations',\n",
       " 'remove_shortwords',\n",
       " 'remove_special_characters',\n",
       " 'remove_stopwords',\n",
       " 'remove_street_address',\n",
       " 'remove_terms_in_bracket',\n",
       " 'remove_urls',\n",
       " 'remove_userhandles',\n",
       " 'remove_visacard_addr',\n",
       " 'replace_bad_quotes',\n",
       " 'replace_currencies',\n",
       " 'replace_currency_symbols',\n",
       " 'replace_dates',\n",
       " 'replace_emails',\n",
       " 'replace_emojis',\n",
       " 'replace_numbers',\n",
       " 'replace_phone_numbers',\n",
       " 'replace_special_characters',\n",
       " 'replace_term',\n",
       " 'replace_urls',\n",
       " 'string',\n",
       " 'term_freq',\n",
       " 'to_txt',\n",
       " 'word_freq',\n",
       " 'word_length_freq']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(nfx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6e5e1f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   Why ? \n",
       "1          Sage Act upgrade on my to do list for tommorow.\n",
       "2        ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...\n",
       "3         Such an eye ! The true hazel eye-and so brill...\n",
       "4          ugh babe.. hugggzzz for u .!  babe naamazed ...\n",
       "                               ...                        \n",
       "34787      have you gift! Hope you like it! It's hand m...\n",
       "34788    The world didnt give it to me..so the world MO...\n",
       "34789                             A man robbed me today . \n",
       "34790    Youu call it JEALOUSY, I call it of #Losing YO...\n",
       "34791    I think about you baby, and I dream about you ...\n",
       "Name: Text, Length: 34792, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2708e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Text']=df['Text'].apply(nfx.remove_userhandles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9ec2916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Clean_Text']=df['Clean_Text'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a44c61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Text</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Why ?</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>joy</td>\n",
       "      <td>Sage Act upgrade on my to do list for tommorow.</td>\n",
       "      <td>Sage Act upgrade list tommorow.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...</td>\n",
       "      <td>WAY HOMEGIRL BABY FUNERAL!!! MAN HATE FUNERALS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>joy</td>\n",
       "      <td>Such an eye ! The true hazel eye-and so brill...</td>\n",
       "      <td>eye ! true hazel eye-and brilliant ! Regular f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>joy</td>\n",
       "      <td>@Iluvmiasantos ugh babe.. hugggzzz for u .!  b...</td>\n",
       "      <td>ugh babe.. hugggzzz u .! babe naamazed nga ako...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34787</th>\n",
       "      <td>34787</td>\n",
       "      <td>surprise</td>\n",
       "      <td>@MichelGW have you gift! Hope you like it! It'...</td>\n",
       "      <td>gift! Hope like it! hand wear ! It'll warm! Lol</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34788</th>\n",
       "      <td>34788</td>\n",
       "      <td>joy</td>\n",
       "      <td>The world didnt give it to me..so the world MO...</td>\n",
       "      <td>world didnt me..so world DEFINITELY cnt away!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34789</th>\n",
       "      <td>34789</td>\n",
       "      <td>anger</td>\n",
       "      <td>A man robbed me today .</td>\n",
       "      <td>man robbed today .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34790</th>\n",
       "      <td>34790</td>\n",
       "      <td>fear</td>\n",
       "      <td>Youu call it JEALOUSY, I call it of #Losing YO...</td>\n",
       "      <td>Youu JEALOUSY, #Losing YOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34791</th>\n",
       "      <td>34791</td>\n",
       "      <td>sadness</td>\n",
       "      <td>I think about you baby, and I dream about you ...</td>\n",
       "      <td>think baby, dream time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34792 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0   Emotion  \\\n",
       "0               0   neutral   \n",
       "1               1       joy   \n",
       "2               2   sadness   \n",
       "3               3       joy   \n",
       "4               4       joy   \n",
       "...           ...       ...   \n",
       "34787       34787  surprise   \n",
       "34788       34788       joy   \n",
       "34789       34789     anger   \n",
       "34790       34790      fear   \n",
       "34791       34791   sadness   \n",
       "\n",
       "                                                    Text  \\\n",
       "0                                                 Why ?    \n",
       "1        Sage Act upgrade on my to do list for tommorow.   \n",
       "2      ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...   \n",
       "3       Such an eye ! The true hazel eye-and so brill...   \n",
       "4      @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...   \n",
       "...                                                  ...   \n",
       "34787  @MichelGW have you gift! Hope you like it! It'...   \n",
       "34788  The world didnt give it to me..so the world MO...   \n",
       "34789                           A man robbed me today .    \n",
       "34790  Youu call it JEALOUSY, I call it of #Losing YO...   \n",
       "34791  I think about you baby, and I dream about you ...   \n",
       "\n",
       "                                              Clean_Text  \n",
       "0                                                      ?  \n",
       "1                        Sage Act upgrade list tommorow.  \n",
       "2      WAY HOMEGIRL BABY FUNERAL!!! MAN HATE FUNERALS...  \n",
       "3      eye ! true hazel eye-and brilliant ! Regular f...  \n",
       "4      ugh babe.. hugggzzz u .! babe naamazed nga ako...  \n",
       "...                                                  ...  \n",
       "34787    gift! Hope like it! hand wear ! It'll warm! Lol  \n",
       "34788    world didnt me..so world DEFINITELY cnt away!!!  \n",
       "34789                                 man robbed today .  \n",
       "34790                      Youu JEALOUSY, #Losing YOU...  \n",
       "34791                             think baby, dream time  \n",
       "\n",
       "[34792 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3044c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfeatures = df['Clean_Text']\n",
    "ylabels = df['Emotion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1dff9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(Xfeatures,ylabels,test_size=0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc460a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11089594",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#logistic regression pipeline\n",
    "pipe_lr = Pipeline(steps=[('cv',CountVectorizer()),('lr',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "534c7c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv', CountVectorizer()), ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train and Fit Data\n",
    "pipe_lr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ce246fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6200421536692853"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check Accuracy\n",
    "pipe_lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "050bcfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing program with this application\n",
    "ex1= \"This boom was so interesting it made me happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "590db0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['joy'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.predict([ex1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6352a8b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.27895719e-03, 1.50980619e-02, 2.10818569e-02, 8.24956946e-01,\n",
       "        5.23614015e-04, 9.94089797e-02, 1.72038365e-04, 3.54795464e-02]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.predict_proba([ex1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f363f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'disgust', 'fear', 'joy', 'neutral', 'sadness', 'shame',\n",
       "       'surprise'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lr.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "caa894c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#block to save model and pipeline\n",
    "import joblib\n",
    "pipeline_file = open(\"emotion_classifier_pie_lr03_june_2021.pkl\",\"wb\")\n",
    "joblib.dump(pipe_lr,pipeline_file)\n",
    "pipeline_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3794e0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
